{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (138.0.7204.94) detected in PATH at /opt/homebrew/bin/chromedriver might not be compatible with the detected chrome version (139.0.7258.67); currently, chromedriver 139.0.7258.68 is recommended for chrome 139.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 1: 24 items (total 24)\n",
      "page 2: 24 items (total 48)\n",
      "page 3: 24 items (total 72)\n",
      "page 4: 24 items (total 96)\n",
      "page 5: 24 items (total 120)\n",
      "page 6: 24 items (total 144)\n",
      "page 7: 24 items (total 168)\n",
      "page 8: 24 items (total 192)\n",
      "page 9: 24 items (total 216)\n",
      "page 10: 24 items (total 240)\n",
      "page 11: 24 items (total 264)\n",
      "page 12: 24 items (total 288)\n",
      "page 13: 24 items (total 312)\n",
      "page 14: 24 items (total 336)\n",
      "page 15: 24 items (total 360)\n",
      "page 16: 24 items (total 384)\n",
      "page 17: 24 items (total 408)\n",
      "page 18: 24 items (total 432)\n",
      "page 19: 24 items (total 456)\n",
      "page 20: 24 items (total 480)\n",
      "page 21: 24 items (total 504)\n",
      "page 22: 24 items (total 528)\n",
      "page 23: 24 items (total 552)\n",
      "page 24: 24 items (total 576)\n",
      "page 25: 24 items (total 600)\n",
      "page 26: 24 items (total 624)\n",
      "page 27: 24 items (total 648)\n",
      "page 28: 24 items (total 672)\n",
      "page 29: 24 items (total 696)\n",
      "page 30: 24 items (total 720)\n",
      "page 31: 24 items (total 744)\n",
      "page 32: 24 items (total 768)\n",
      "page 33: 24 items (total 792)\n",
      "page 34: 24 items (total 816)\n",
      "page 35: 24 items (total 840)\n",
      "page 36: 24 items (total 864)\n",
      "page 37: 24 items (total 888)\n",
      "page 38: 24 items (total 912)\n",
      "page 39: 24 items (total 936)\n",
      "page 40: 24 items (total 960)\n",
      "page 41: 24 items (total 984)\n",
      "page 42: 24 items (total 1008)\n",
      "page 43: 24 items (total 1032)\n",
      "page 44: 24 items (total 1056)\n",
      "page 45: 24 items (total 1080)\n",
      "page 46: 24 items (total 1104)\n",
      "page 47: 24 items (total 1128)\n",
      "page 48: 24 items (total 1152)\n",
      "page 49: 24 items (total 1176)\n",
      "page 50: 24 items (total 1200)\n",
      "page 51: 24 items (total 1224)\n",
      "page 52: 24 items (total 1248)\n",
      "page 53: 24 items (total 1272)\n",
      "page 54: 24 items (total 1296)\n",
      "page 55: 24 items (total 1320)\n",
      "page 56: 24 items (total 1344)\n",
      "page 57: 24 items (total 1368)\n",
      "page 58: 24 items (total 1392)\n",
      "page 59: 24 items (total 1416)\n",
      "page 60: 24 items (total 1440)\n",
      "page 61: 24 items (total 1464)\n",
      "page 62: 24 items (total 1488)\n",
      "page 63: 24 items (total 1512)\n",
      "page 64: 24 items (total 1536)\n",
      "page 65: 24 items (total 1560)\n",
      "page 66: 24 items (total 1584)\n",
      "page 67: 24 items (total 1608)\n",
      "page 68: 24 items (total 1632)\n",
      "page 69: 24 items (total 1656)\n",
      "page 70: 24 items (total 1680)\n",
      "page 71: 24 items (total 1704)\n",
      "page 72: 24 items (total 1728)\n",
      "page 73: 24 items (total 1752)\n",
      "page 74: 24 items (total 1776)\n",
      "page 75: 24 items (total 1800)\n",
      "done: 1800\n"
     ]
    }
   ],
   "source": [
    "chrome_options = Options()\n",
    "\n",
    "chrome_options.add_experimental_option(\"detach\", True)\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\",[\"enable-logging\"])\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "#base_url = 'https://www.metacritic.com/browse/game/pc/all/all-time/userscore/?releaseYearMin=1958&releaseYearMax=2025&platform=pc&page=1'\n",
    "#url = base_url\n",
    "#driver.get(url)\n",
    "#driver.maximize_window()\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "title_nodes = soup.select('div.c-finderProductCard_title[data-title]')\n",
    "titles = [n['data-title'].strip() for n in title_nodes]\n",
    "#data_rows = soup.find_all('div', class_='c-finderProductCard_title') #find_all은 리스트로 가져옴\n",
    "# data_rows = parent.find_all('h3', class_='c-finderProductCard_titleHeading')\n",
    "BASE = (\"https://www.metacritic.com/browse/game/pc/all/all-time/userscore/\"\n",
    "        \"?releaseYearMin=1958&releaseYearMax=2025&platform=pc&page={page}\")\n",
    "\n",
    "all_names = []\n",
    "\n",
    "for page in range(1,76):  # 1 ~ 75\n",
    "    url = BASE.format(page=page)\n",
    "    driver.get(url)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    # 목록 로드 대기 (타이틀 div가 뜰 때까지)\n",
    "    WebDriverWait(driver, 12).until(\n",
    "        EC.presence_of_all_elements_located(\n",
    "            (By.CSS_SELECTOR, 'div.c-finderProductCard_title[data-title]')\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # data-title 속성만 추출하면 번호 없이 깔끔\n",
    "    elems = driver.find_elements(By.CSS_SELECTOR, 'div.c-finderProductCard_title[data-title]')\n",
    "    names = [e.get_attribute('data-title').strip() for e in elems]\n",
    "    all_names.extend(names)\n",
    "\n",
    "    print(f\"page {page}: {len(names)} items (total {len(all_names)})\")\n",
    "    time.sleep(0.5)  # 서버에 예의 + 로딩 여유\n",
    "\n",
    "# 저장(선택)\n",
    "pd.DataFrame({'title': all_names}).to_csv('metacritic_pc_userscore_green.csv', index=False)\n",
    "print(\"done:\", len(all_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "webtoon_list = []\n",
    "weekend_dic = {0:'토요일', 1:'일요일'}\n",
    "url = 'https://comic.naver.com/webtoon?tab=sat'\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(2)\n",
    "try:\n",
    "    driver.maximize_window()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for weekend in range(2):\n",
    "    # 페이지를 가장 아래까지 스크롤하는 방법\n",
    "\n",
    "    interval = 1 # 1초에 한번씩 스크롤 내림\n",
    "\n",
    "    # 현재 문서 높이를 가져와서 저장\n",
    "    prev_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    # 반복 수행\n",
    "    while True:\n",
    "        # 스크롤을 가장 아래로 내림\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "\n",
    "        # 페이지 로딩 대기\n",
    "        time.sleep(interval)\n",
    "\n",
    "        # 현재 문서 높이를 가져와서 저장\n",
    "        curr_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if curr_height == prev_height:\n",
    "            break\n",
    "\n",
    "        prev_height = curr_height\n",
    "\n",
    "    # 해당 Xpath 정보를 확인할때까지 5초간 기다림, 5초후에도 해당 Xpath를 찾지 못하면 에러 반환\n",
    "    # elem = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"content\"]/div[1]/ul/li[40]/a/div/img')))\n",
    "\n",
    "    columns = ['weekend', 'name', 'author', 'rate']         # 웹툰이름, 웹툰작가, 웹툰평점, 정보 크롤링\n",
    "    values = []                                             # 토요일 웹툰 리스트와 일요일 웹툰 리스트 정보를 담을 빈 리스트 생성\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')        # 현재 브라우저의 page의 html 정보를 가져오기\n",
    "    data_rows = soup.find_all('li', attrs={'class':'item'}) # 해당 조건에 맞는 정보들을 list로 반환\n",
    "\n",
    "    for i, row in enumerate(data_rows):                     # data_rows 리스트에 있는 값들과 인덱스를 차례대로 가져온다\n",
    "\n",
    "        print('{0} {1}번째 웹툰정보 크롤링'.format(weekend_dic[weekend], i+1))\n",
    "        blank = []\n",
    "        blank.append(weekend_dic[weekend])\n",
    "\n",
    "        name = row.find('span', attrs={'class':'ContentTitle__title--e3qXt'})       # 웹툰이름 가져오기\n",
    "        if name:                                                                    # 해당 조건에 맞는 정보가 하나라도 있을 경우:\n",
    "            name = name.get_text().strip()                                          # html에서 텍스트만 가져온 뒤 공백 제거\n",
    "            blank.append(name)\n",
    "        else:                                                                       # 해당 조건에 맞는 정보가 하나도 없을 경우:\n",
    "            blank.append('Something is wrong')\n",
    "            print('{}번째 웹툰이름 가져올때 문제발생'.format(i+1))\n",
    "            continue\n",
    "\n",
    "\n",
    "        author = row.find('a', attrs={'class':'ContentAuthor__author--CTAAP'})      # 웹툰작가 가져오기\n",
    "        if author:\n",
    "            author = author.get_text().strip()\n",
    "            blank.append(author)\n",
    "        else:\n",
    "            blank.append('Something is wrong')\n",
    "            print('{}번째 웹툰작가 가져올때 문제발생'.format(i+1))\n",
    "            continue\n",
    "\n",
    "\n",
    "        rate = row.find('span', attrs={'class':'Rating__star_area--dFzsb'})        # 웹툰평점 가져오기\n",
    "        if rate:\n",
    "            rate = rate.find('span', attrs={'class':'text'}).get_text().strip()    # class가 Rating__star_area--dFzsb인 span 태그 안에 있는 span 태그에서 텍스트 가져오기\n",
    "            blank.append(rate)\n",
    "        else:\n",
    "            blank.append('Something is wrong')\n",
    "            print('{}번째 웹툰평점 가져올때 문제발생'.format(i+1))\n",
    "            continue\n",
    "\n",
    "        values.append(blank)\n",
    "        print('---------------------------------------------------')\n",
    "\n",
    "    sunday_webtoon_button = driver.find_element(By.XPATH, '//*[@id=\"wrap\"]/header/div[3]/nav/ul/li[8]/a') # 일요일 웹툰 클릭\n",
    "    sunday_webtoon_button.click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    df = pd.DataFrame(values, columns = columns)\n",
    "    webtoon_list.append(df) # 최종적으로 [[토요일 웹툰 정보 리스트들], [일요일 웹툰 정보 리스트들]] 형태로 반환됨\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
